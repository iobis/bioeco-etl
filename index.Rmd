---
title: GOOS BioEco portal data loading
date: "`r Sys.Date()`"
author: Pieter Provoost
output: (function(...) {
  rmdformats::robobook(toc_depth = 3, pandoc_args = c("+RTS", "-K2000m", "-RTS"), ...) })
editor_options: 
  chunk_output_type: console
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs") })  
---

This is an updated version of the original notebook which aims to export data for import into GeoNode.

# Load packages

```{r warning = FALSE, message = FALSE}
library(ggplot2)
library(sf)
library(mapview)
library(rnaturalearth)
library(dplyr)
library(geojsonio)
library(DBI)
library(lubridate)
library(stringr)
library(tidyr)
library(readr)
library(smoothr)
library(xlsx)
library(purrr)
library(glue)
library(geojsonsf)
```

# Original dataset

## Read and combine CSV files

Read and combine the two CSV files provided by Erin. Parse dates and recode temporal frequency. Some records have GeoJSON geometries, these are stored in the `geometry_geojson` column which will be used later on for export as shapefile.

```{r warning = FALSE, message = FALSE}
df_source_2 <- read.csv("data/2InfoDataProviderswoSpatialInfo_Final_420_7302020_FINAL_toshare.csv") %>%
  select(
    ErinSpatialGeoJSON,
    name = prog_name,
    contact_firstname = resp_firstname,
    contact_lastname = resp_lastname,
    contact_email = resp_email
  ) %>%
  mutate_all(list(~na_if(., ""))) %>%
  rename(geometry_geojson = ErinSpatialGeoJSON)
```

```{r warning = FALSE, message = FALSE}
df_source_4 <- read.csv("data/4Updated_Spatial_Survey_420_8132020_FINAL_toshare.csv")
```

```{r warning = FALSE, message = FALSE}
df_initial <- df_source_4 %>%
  select(
    name = prog_name,
    abstract = prog_name,
    abbreviation = prog_abbrev,
    url = prog_url,
    start_date = duration_start_year,
    end_date = duration_end_year,
    temporal_resolution = freq_interval,
    eov_birds = Birds,
    eov_hardcoral = Hard_Coral,
    eov_fish = Fish,
    eov_macroalgae = Macroalgae,
    eov_mangroves = Mangroves,
    eov_microbes = Microbes,
    eov_oceansound = Ocean_Sound,
    eov_phytoplankton = Phytoplankton,
    eov_seagrass = Seagrass,
    eov_seaturtles = Sea_Turtles,
    eov_zooplankton = Zooplankton,
    eov_benthicinvertebrates = Benthic_Invertebrate,
    eov_mammals = Marine_Mammals
  ) %>%
  left_join(df_source_2, by = "name") %>%
  mutate_at(vars(matches("eov")), ~ifelse(is.na(.), FALSE, TRUE)) %>%
  mutate(
    url = str_trunc(url, 200),
    source = "initial",
    start_date = as.Date(parse_date_time(start_date, orders = "y")),
    end_date = ceiling_date(as.Date(parse_date_time(end_date, orders = "y")), "year") - days(1),
    temporal_resolution = recode(
      temporal_resolution,
      "Sub-daily" = "sub_daily",
      "Daily" = "daily",
      "Monthly (12x per year)" = "monthly",
      "Quarterly (4x per year)" = "quarterly",
      "2x per year" = "twice_per_year",
      "1x per year" = "annually",
      "1x every 2 to 5 years" = "every_2_to_5_years",
      "1x every 6-10 years" = "every_6_to_10_years",
      "1x every >10 years" = "every_10_years_or_more",
      "Opportunistically/highly irregular intervals" = "opportunistically"
    )
  ) %>%
  as_tibble()

df_initial
```

## Fix missing network/EOV links

```{r warning = FALSE, message = FALSE}
df_initial$eov_benthicinvertebrates[which(df_initial$name == "Aleutian Islands Benthic Habitat Survey")] <- TRUE
```

# EuroSea data

A second dataset has been provided by EuroSea. Read the Excel file.

```{r warning=FALSE, message=FALSE}
df_source_eurosea <- read.xlsx("data/EuroSea.xlsx", 1)

df_eurosea <- df_source_eurosea %>%
  select(
    country = Country,
    organization = Organisation,
    name = Program.name,
    location = Programs.Location,
    time = Time.period,
    frequency = Frequency,
    eov_birds = Birds,
    eov_hardcoral = Hard.coral,
    eov_fish = Fish,
    eov_macroalgae = Macroalgae,
    eov_mangroves = Mangrove,
    eov_microbes = Microbes,
    eov_phytoplankton = Phytoplankton,
    eov_seagrass = Seagrass,
    eov_seaturtles = Turtles,
    eov_zooplankton = Zooplankton,
    eov_benthicinvertebrates = Benthic.invertebrates,
    eov_mammals = Mammals,
    url = Website,
    lat = Lat,
    lon = Lon
  ) %>%
  filter(!is.na(name)) %>%
  as_tibble()

df_eurosea
```

Convert boolean columns:

```{r warning=FALSE, message=FALSE}
df_eurosea <- df_eurosea %>%
  mutate_at(vars(matches("eov")), ~ifelse(!is.na(.) & . == "x", TRUE, FALSE))
```

The `time` column contains dash separated start and end years (or `current`). Split into separate columns and convert to numeric.

```{r warning=FALSE, message=FALSE}
df_eurosea <- df_eurosea %>%
  separate(time, c("start_date", "end_date")) %>%
  mutate(across(c("start_date", "end_date"), as.numeric)) %>%
  mutate(across(c("start_date", "end_date"), as.character)) %>%
  mutate(
    start_date = as.Date(parse_date_time(start_date, orders = "y")),
    end_date = ceiling_date(as.Date(parse_date_time(end_date, orders = "y")), "year") - days(1)
  )
```

Recode temporal frequency:

```{r warning=FALSE, message=FALSE}
df_eurosea <- df_eurosea %>%
  mutate(
    temporal_resolution = recode(
      frequency,
      "2 x a week since 2005" = "weekly", 
      "Annual (Sept)" = "annually", 
      "Annual (Aug - Sept)" = "annually", 
      "2x per year" = "twice_per_year", 
      "Continually" = "sub_daily", 
      "Annual" = "annually", 
      "Monthly" = "monthly", 
      "Daily" = "daily", 
      "Quarterly" = "quarterly", 
      "Spring/Summer" = "twice_per_year", 
      "Once in 3 years" = "every_2_to_5_years", 
      "Once in 6 years" = "every_6_to_10_years", 
      "4x per year" = "quarterly", 
      "Once in 2 years" = "every_2_to_5_years", 
      "Varies" = "opportunistically", 
      "Every 6 months" = "twice_per_year", 
      "A" = "annually", 
      "Annually in May" = "annually", 
      "Annually" = "annually", 
      "Annually in March/April" = "annually", 
      "Annually in July/August" = "annually", 
      "6-8y interval (1987, 1989, 1995, 2001, 2007,2015)" = "every_6_to_10_years", 
      "Annually in March" = "annually", 
      "Annually in August" = "annually", 
      "Annually in September" = "annually", 
      "Every 3 years" = "every_2_to_5_years", 
      "1x per year" = "annually", 
      "weekly" = "weekly", 
      "2x per month" = "monthly", 
      "4x per month" = "weekly", 
      "1x per month" = "monthly", 
      "Year round" = "opportunistically", 
      "Seasonal" = "quarterly", 
      "10 minutes" = "sub_daily", 
      "Seconds" = "sub_daily", 
      "Once per summer (cruise) + autonomous instruments throughout the year" = "sub_daily",
      "Annual or Seasonal" = "annually", 
      "Weekly" = "weekly", 
      "Monthly to biannually" = "opportunistically", 
      "May and June " = "twice_per_year", 
      "Monthly to bimonthly" = "monthly", 
      "Seasonally" = "quarterly", 
      "Weekly from May to October" = "opportunistically", 
      "June-Sept" = "opportunistically", 
      "Summer" = "annually", 
      "weekly or bi-weekly " = "weekly", 
      "All year round but mostly from April to October" = "opportunistically", 
      "8-10x month" = "weekly", 
      "March - November" = "opportunistically", 
      "once in 2 years" = "every_2_to_5_years", 
      "once prt year" = "annually", 
      "once in 6 year period" = "every_6_to_10_years", 
      "Every 3 months" = "quarterly", 
      "Every 2 years" = "every_2_to_5_years", 
      "Once a month" = "monthly", 
      "April - October (weather dependent)" = "opportunistically", 
      "Once per summer" = "annually", 
      "Varies/Daily " = "opportunistically", 
      "4 - 10 times a year" = "quarterly", 
      "3 - 6 times a year" = "quarterly", 
      "3 - 4 times a year" = "quarterly", 
      "Twice a month" = "monthly", 
      "Opportunistic" = "opportunistically", 
      "4 times a year" = "quarterly", 
      "Every 10 days in spring/summer and monthy in winter" = "monthly", 
      "Annualy" = "annually", 
      "4 per year (1 per season)" = "quarterly", 
      "6-8 x per year (1 mission of 2 months length approx.)" = "quarterly", 
      "4 x per year" = "quarterly", 
      "24 x per year" = "monthly", 
      "10x per year" = "monthly", 
      "Planned with 3 years intervals" = "every_2_to_5_years", 
      "Biannual" = "every_2_to_5_years", 
      "Annual/Biannual" = "every_2_to_5_years", 
      "2-4 times per year" = "annually", 
      "Bi-monthly" = "monthly", 
      "2 weekly / monthly" = "monthly" 
    )
  ) %>%
  select(-frequency)
```

The latitude and longitude columns contain variety of formats, for now I'm only parsing singular decimal degrees values. Geometries are stored in `geometry_geojson`.

```{r warning=FALSE, message=FALSE}
df_eurosea <- df_eurosea %>%
  mutate(across(c("lon", "lat"), as.numeric)) %>%
  mutate(
    lon = ifelse(is.na(lat), NA, lon),
    lat = ifelse(is.na(lon), NA, lat)
  ) %>%
  mutate(geometry_sfc = st_as_sfc(ifelse(!is.na(lon), paste0("POINT(", lon, " ", lat, ")"), "POINT EMPTY")))
```

Merge by network:

```{r warning=FALSE, message=FALSE}
concat <- function(x, collapse = ";") {
  x <- gsub("\\s+", " ", trimws(unique(x[!is.na(x)])))
  if (length(x) == 0) return(NA)
  return(paste0(x, collapse = collapse))
}

frequencies <- c(
  "sub_daily", 
  "daily", 
  "monthly", 
  "quarterly", 
  "twice_per_year", 
  "annually", 
  "every_2_to_5_years", 
  "every_6_to_10_years", 
  "every_10_years_or_more", 
  "opportunistically"
)

df_eurosea <- df_eurosea %>%
  filter(!is.na(name)) %>%
  mutate(temporal_resolution = factor(temporal_resolution, levels = frequencies)) %>%
  group_by(organization, name) %>%
  summarize(
    start_date = min(start_date, na.rm = TRUE),
    end_date = max(end_date, na.rm = TRUE),
    eov_birds = as.logical(max(eov_birds)),
    eov_hardcoral = as.logical(max(eov_hardcoral)),
    eov_fish = as.logical(max(eov_fish)),
    eov_macroalgae = as.logical(max(eov_macroalgae)),
    eov_mangroves = as.logical(max(eov_mangroves)),
    eov_microbes = as.logical(max(eov_microbes)),
    eov_phytoplankton = as.logical(max(eov_phytoplankton)),
    eov_seagrass = as.logical(max(eov_seagrass)),
    eov_seaturtles = as.logical(max(eov_seaturtles)),
    eov_zooplankton = as.logical(max(eov_zooplankton)),
    eov_benthicinvertebrates = as.logical(max(eov_benthicinvertebrates)),
    eov_mammals = as.logical(max(eov_mammals)),
    url = concat(url, collapse = "; "),
    abstract = concat(c(organization, name), collapse = " - "),
    temporal_resolution = levels(temporal_resolution)[min(as.numeric(temporal_resolution), na.rm = TRUE)],
    geometry_geojson = as.character(sfc_geojson(st_union(geometry_sfc)))
  ) %>%
  ungroup() %>%
  mutate(
    source = "eurosea",
    url = str_trunc(url, 500),
  )

df_eurosea
```

# Combine data

```{r warning=FALSE, message=FALSE}
df_combined <- bind_rows(df_initial, df_eurosea) %>%
  mutate(id = row_number(), has_shapefile = FALSE)
```

## Assign identifiers

```{r warning=FALSE, message=FALSE}
make_identifier <- function(name) {
  name %>%
    tolower() %>%
    str_replace_all("[()\":\',&/\\.;]", "") %>%
    str_trim() %>%
    str_replace_all("[\\s-–]+", "_") %>%
    iconv(from = "UTF-8", to = "ASCII//TRANSLIT") %>%
    str_replace_all("[()\":\',&/\\.^`]", "")
}

df_combined <- df_combined %>%
  mutate(identifier = make_identifier(name))

df_combined
```

Let's check if there are any duplicate datasets:

```{r warning=FALSE, message=FALSE}
duplicates <- df_combined[duplicated(df_combined$identifier) | duplicated(df_combined$identifier, fromLast = TRUE),]
duplicates %>%
  select(id, name, source, abstract, url, start_date, end_date, temporal_resolution, contact_email, organization, identifier) %>%
  arrange(identifier) %>%
  knitr::kable()
```

`r emo::ji("fire")` A `_duplicate` suffix is being added to identifiers for datasets with duplicate names.

```{r warning=FALSE, message=FALSE}
df_combined$original_identifier <- df_combined$identifier

df_combined$identifier[duplicated(df_combined$identifier)] <- paste0(df_combined$identifier[duplicated(df_combined$identifier)], "_duplicate")
```

# Process spatial data in the geojson column

This exports GeoJSON from the `geometry_geojson` column to shapefiles. `r emo::ji("fire")` Mixed geometries cannot be exported and are skipped.

```{r warning = FALSE, message = FALSE}
for (i in 1:nrow(df_combined)) {
  identifier <- df_combined$identifier[i]
  if (!is.na(df_combined$geometry_geojson[i]) & df_combined$geometry_geojson[i] != "null") {
    output_folder <- glue("output/{identifier}/")
    if (!file.exists(output_folder)) dir.create(output_folder)
    filename_shapefile <- glue("output/{identifier}/{identifier}.shp")
    shape <- df_combined$geometry_geojson[i] %>%
      geojson_sf()
    if (length(unique(st_geometry_type(shape))) == 1) {
      shape %>%
        write_sf(filename_shapefile, layer = identifier)
      df_combined$has_shapefile[df_combined$identifier == identifier] <- TRUE
    }
  }
}
```

# Process external spatial data sources
## CSV files

For some records of the initial dataset, spatial information is provided in CSV files. Let's process these into shapefiles. Shapefiles are added by all datasets in case of duplicate names.

```{r warning = FALSE, message = FALSE}
shapefile_from_points <- function(name, filename_csv, coords) {
  identifiers <- df_combined$identifier[which(df_combined$name == name)]
  for (identifier in identifiers) {
    df_combined$has_shapefile[df_combined$identifier == identifier] <<- TRUE
    output_folder <- glue("output/{identifier}/")
    if (!file.exists(output_folder)) dir.create(output_folder)
    filename_shapefile <- glue("output/{identifier}/{identifier}.shp")
    if (!file.exists(filename_shapefile)) {
      message(glue("Processing CSV file to {filename_shapefile}"))
      read.csv(filename_csv) %>%
        st_as_sf(coords = coords, crs = 4326, remove = FALSE) %>%
        filter(Latitude <= 90) %>%
        write_sf(filename_shapefile, layer = identifier)
    }
  }
}
```

```{r warning = FALSE, message = FALSE}
shapefile_from_points("Aleutian Islands Benthic Habitat Survey", "data/largeCSVsites_final/Aleutian Islands Benthic Habitat Survey.csv", c("Longitude", "Latitude"))
shapefile_from_points("Australian continuous plankton recorder survey (AusCPR)", "data/largeCSVsites_final/Australian continuous plankton recorder survey (AusCPR).csv", c("MID_LONGITUDE", "MID_LATITUDE"))
shapefile_from_points("Cetacean Research Program", "data/largeCSVsites_final/Cetacean Research Program.csv", c("Longitude", "Latitude"))
shapefile_from_points("Diversity of the Indo-Pacific Network", "data/largeCSVsites_final/Diversity of the Indo-Pacific Network.csv", c("Longitude", "Latitude"))
shapefile_from_points("eOceans", "data/largeCSVsites_final/eOceans.csv", c("Longitude", "Latitude"))
shapefile_from_points("Estacion Costera de Investigaciones Marinas", "data/largeCSVsites_final/Estacion Costera de Investigaciones Marinas.csv", c("Longitude", "Latitude"))
shapefile_from_points("Estación de Fotobiologia Playa Unión", "data/largeCSVsites_final/Estacion de Fotobiologia Playa Union.csv", c("Longitude", "Latitude"))
shapefile_from_points("Global ARMS Program", "data/largeCSVsites_final/Global ARMS Program.csv", c("Longitude", "Latitude"))
shapefile_from_points("IMOS ships of opportunity bioacoustics", "data/largeCSVsites_final/IMOS ships of opportunity bioacoustics.csv", c("Longitude", "Latitude"))
shapefile_from_points("Marine Biodiversity and Climate Change", "data/largeCSVsites_final/Marine Biodiversity and Climate Change.csv", c("Longitude", "Latitude"))
shapefile_from_points("Movebank", "data/largeCSVsites_final/Movebank.csv", c("Longitude", "Latitude"))
shapefile_from_points("National Observatory System: Mammals as Ocean Samplers", "data/largeCSVsites_final/National Observatory System- Mammals as Ocean Samplers.csv", c("Longitude", "Latitude"))
shapefile_from_points("Ocean Tracking Network", "data/largeCSVsites_final/Ocean Tracking Network.csv", c("Longitude", "Latitude"))
shapefile_from_points("Reef Life Survey", "data/largeCSVsites_final/Reef Life Survey.csv", c("Longitude", "Latitude"))
shapefile_from_points("SCAR Southern Ocean Continuous Plankton Recorder Survey", "data/largeCSVsites_final/SCAR Southern Ocean Continuous Plankton Recorder Survey.csv", c("Longitude", "Latitude"))
shapefile_from_points("Service National d'Observation CORAIL", "data/largeCSVsites_final/Service National d_Observation CORAIL.csv", c("Longitude", "Latitude"))
shapefile_from_points("Synoptic Intertidal Benthic Survey", "data/largeCSVsites_final/Synoptic Intertidal Benthic Survey.csv", c("Longitude", "Latitude"))
shapefile_from_points("Tohoku National Fisheries Institute", "data/largeCSVsites_final/Tohoku National Fisheries Institute.csv", c("Longitude", "Latitude"))
shapefile_from_points("Waddenmozaiek program", "data/largeCSVsites_final/Waddenmozaiek program.csv", c("Longitude", "Latitude"))
shapefile_from_points("Zooplankton Sample Collectionof Fisheries Research Agency", "data/largeCSVsites_final/Zooplankton Sample Collectionof Fisheries Research Agency.csv", c("Longitude", "Latitude"))
```

## Other spatial files
### Ecological impact monitoring offshore windfarms

For this network a folder with several shapefiles was provided. Here I'm joining the shapefiles of type polygon into a single shapefile.

```{r warning=FALSE, message=FALSE}
gather_shapefiles <- function(name, folder) {
  files <- list.files(path = folder, pattern = ".shp$", recursive = TRUE)
  shapefiles <- file.path(folder, files) %>%
    purrr::map(read_sf) %>%
    purrr::keep(function(x) { st_geometry_type(x$geometry[1]) == "POLYGON" })
  shape <- bind_rows(shapefiles)
  identifiers <- df_combined$identifier[which(df_combined$name == name)]
  for (identifier in identifiers) {
    new_folder <- glue("output/{identifier}")
    dir.create(new_folder)
    write_sf(shape, glue("{new_folder}/{identifier}.shp"))
    df_combined$has_shapefile[df_combined$identifier == identifier] <<- TRUE
  }
}

gather_shapefiles("Ecological impact monitoring offshore windfarms", "data/eurosea_spatial/Ecological impact monitoring offshore windfarms/")
```

### IUCN IMMA

Warning: these data are loaded from a version with topologies fixed using QGIS.

```{r warning=FALSE, message=FALSE}
copy_shapefile <- function(name, shapefile) {
  identifiers <- df_combined$identifier[which(df_combined$name == name)]
  for (identifier in identifiers) {
    new_folder <- glue("output/{identifier}")
    dir.create(new_folder)
    shape <- read_sf(shapefile)
    write_sf(shape, glue("{new_folder}/{identifier}.shp"))
    df_combined$has_shapefile[df_combined$identifier == identifier] <<- TRUE
  }
}

copy_shapefile("IUCN Marine Mammal Protected Areas Task Force", "data/eurosea_spatial/iucn-imma-layer-shapefile_v2.4/iucn-imma-fixed/iucn-imma_oct20-fixed.shp")
```

### Finland

Warning: the mapping between shapefiles and networks is unclear, this is just an attempt to map some of the files.

```{r warning=FALSE, message=FALSE}
copy_shapefile("Marine breeding birds", "data/eurosea_spatial/Finland/Finland biological monitoring stations/Breeding_seabirds.shp")
copy_shapefile("Coastal waters soft bottom fauna", "data/eurosea_spatial/Finland/Finland biological monitoring stations/Coastal_benthic_invertebrates.shp")
copy_shapefile("Abundance and distribution of harbour porpoises", "data/eurosea_spatial/Finland/Finland biological monitoring stations/Harbour_porpoise_detectors.shp")
copy_shapefile("Coastal hard bottom macroalgae and blue mussel communities", "data/eurosea_spatial/Finland/Finland biological monitoring stations/Macroalgae.shp")
copy_shapefile("Offshore soft bottom macrozoobenthos", "data/eurosea_spatial/Finland/Finland biological monitoring stations/Offshore_benthic_invertebrates.shp")
copy_shapefile("Phytoplankton species composition and abundance", "data/eurosea_spatial/Finland/Finland biological monitoring stations/Phytoplankton.shp")
copy_shapefile("Sea trout", "data/eurosea_spatial/Finland/Finland biological monitoring stations/Seatrout_rivers.shp")
copy_shapefile("Zooplankton species composition and abundance", "data/eurosea_spatial/Finland/Finland biological monitoring stations/Zooplankton.shp")
```

### Spain

```{r warning=FALSE, message=FALSE}
identifiers <- df_combined$identifier[which(df_combined$name == "Basque monitoring network for the ecological status assessment")]

for (identifier in identifiers) {
  new_folder <- glue("output/{identifier}")
  dir.create(new_folder)
  read_tsv("data/eurosea_spatial/Spain/Basque monitoring network for the ecological status assessment.tsv") %>%
    st_as_sf(coords = c("x", "y"), crs = "EPSG:32630", remove = FALSE) %>%
    st_transform(crs = "EPSG:4326") %>%
    write_sf(glue("{new_folder}/{identifier}.shp"), layer = identifier)
  df_combined$has_shapefile[df_combined$identifier == identifier] <- TRUE
}
```

### WESPAS 2020

```{r warning=FALSE, message=FALSE}
identifiers <- df_combined$identifier[which(df_combined$name == "Western European Shelf Pelagic Acoustic Survey (WESPAS)")]

for (identifier in identifiers) {
  new_folder <- glue("output/{identifier}")
  dir.create(new_folder)
  read.xlsx("data/eurosea_spatial/WESPAS 2020_Positions.xlsx", 1) %>%
    st_as_sf(coords = c("Long.Deg", "Lat.Deg"), crs = 4326) %>%
    st_coordinates() %>%
    st_linestring() %>%
    st_sfc() %>%
    st_sf() %>%
    write_sf(glue("{new_folder}/{identifier}.shp"), layer = identifier)
  df_combined$has_shapefile[df_combined$identifier == identifier] <- TRUE
}
```

### Germany

This was not processed as the mapping is unclear.

### Latvia

Not processed yet, coordinates need to be converted.

# Missing spatial data

```{r warning=FALSE, message=FALSE}
missing_spatial <-df_combined %>%
  filter(has_shapefile == FALSE)

missing_spatial %>%
  select(name, identifier, url) %>%
  arrange(identifier) %>%
  knitr::kable()
```

## Generate empty spatial files

```{r warning=FALSE, message=FALSE}
for (identifier in missing_spatial$identifier) {
  new_folder <- glue("output/{identifier}")
  dir.create(new_folder)
  st_sf(st_sfc(crs = 4326)) %>%
    write_sf(glue("{new_folder}/{identifier}.shp"), layer = identifier)
}
```
